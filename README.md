# DL2025_HW3


# задача 1
Recall@5: 0.9880952380952381

MRR: 0.8685626102292769

# задача 2
Recall@1: 0.726

Recall@3: 0.871

Recall@10: 0.925

MRR: 0.8025492338721569

Вывод: Метрики показывают, что TF-IDF хорошо находит частично релевантные ответы, но плохо справляется с синонимами, перефразировками и нечестких формулировках

# задача 3
Recall@1: 0.912

Recall@3: 0.965

Recall@10: 0.985

MRR: 0.9421976733696289

Вывод:
Модель E5 работает лучше, чем TF-IDF. Она понимает смысл, а не просто ищет пересечение слов

# Задача 4

Результаты для Contrastive Loss:

Recall@1: 0.4167

Recall@3: 0.6667

Recall@10: 0.8611

MRR: 0.5727


Результаты для Triplet Loss:

Recall@1: 0.2083

Recall@3: 0.3750

Recall@10: 0.7361

MRR: 0.3605


Результаты для Vanilla E5:

Recall@1: 0.3750

Recall@3: 0.5556

Recall@10: 0.7500

MRR: 0.4999


Вывод: Contrastive Loss - лидер по всем метрикам. Модель научилась ставить правильные документы ближе к началу списка.

Triplet Loss - сильно отстал, особенно в Recall@1 и MRR.

Vanilla E5 - неплохой базовый уровень, но уступил дообученной Contrastive-модели

Recall@1 поднялся с 0.375 до 0.4167,MRR с 0.4999 до 0.5727

Дообучение на конкретном датасете помогло модели лучше ориентироваться в домене Natural Questions, где совпадения могут быть более контекстуальными


# Задача 5
